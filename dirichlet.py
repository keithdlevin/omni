
import numpy as np
import scipy.linalg as spla
import scipy.special as spsp
import copy

def dirimix_edgeden_E( K, alpha1, alpha0 ):
    '''
    Compute the expected edge density when latent positions are drawn
    iid from our mixture of Dirichlets:
    X_1 is generated by
	1) Draw k from unif( [1,2,...,K] )
        2) Set alphavec[k]=alpha1, alphavec[i]=alpha0 for the rest.
	3) Draw Y ~ Diri( alphavec )
	4) Z ~ Beta( K-1, 1 ), return X=Z Y.

    E (X_1^T X_2)
    = E Y_1^2 Y_2^2 E (Z_1^T Z_2)
    = [ E Y_1^2 ]^2 E E[ (Z_1^T Z_2) | k_1,k_2,k_3 ]
    Now, E[ (Z_1^T Z_2) | k ]
	= dirichlet_triden_E( alphavec(k) ),
	where alphavec(k) = [alpha0, alpha0,...,alpha1,...alpha0]
    By symmetry,
    E E[ (Z_1^T Z_2) | k ]
	= Dir( alphavec(k) ) for any k.
    Also, we have for Beta(a,b)
    E Y_1^2 = var(a,b) + mean( a,b)^2,

    Checked via simulation, May 12
    '''

    betamean = beta_mean( K-1, 1 )
    EY = betamean

    # For every combination of mixture assignments, add probability
    diri_denE_mixture = 0.0
    # E X_1 ^T X_2 = mu1^T mu2 where mu1 = E X_1, etc.
    for k1 in range(K):
        alphavec1 = alpha0*np.ones( K )
        alphavec1[k1] = alpha1
        # Now compute Q, as in dirichlet_triden_E
        mu1 = compute_diri_mean( alphavec1 )
        for k2 in range(K):
            alphavec2 = alpha0*np.ones( K )
            alphavec2[k2] = alpha1
            mu2 = compute_diri_mean( alphavec2 )
            # Now, computing E X_1^T X_2 is an inner product
            diri_denE_mixture += np.dot( mu1, mu2 )/(K**2)

    return EY**2 * diri_denE_mixture

def dirichlet_edgedensity_E( alphavec ):
    '''
    Compute the expected edge density when LPs are drawn iid Dir( alphavec ).

    alphavec : numpy array encoding a Dirichlet distribution

    Returns: E X^T Y where X,Y ~ Dir( alphavec ) independently.
    '''
    mu = compute_diri_mean( alphavec )
    return np.dot( mu, mu )

def beta_mean( a,b ):
    '''
    Compute the mean of a Beta(a,b).
    '''
    return a/(a+b)

def beta_var( a,b ):
    '''
    Compute variance of a Beta(a,b)
    '''
    return a*b/((a+b)**2 * (a+b+1) )

def dirimix_triden_E( K, alpha1, alpha0 ):
    '''
    Compute the expected triangle density when latent positions are drawn
    iid from our mixture of Dirichlets:
    X_1 is generated by
	1) Draw k from unif( [1,2,...,K] )
        2) Set alphavec[k]=alpha1, alphavec[i]=alpha0 for the rest.
	3) Draw Y ~ Diri( alphavec )
	4) Z ~ Beta( K-1, 1 ), return X=Z Y.

    E (X_1^T X_2)(X_1^T X_3)(X_2^T X_3)
    = E Y_1^2 Y_2^2 Y_3^2 E (Z_1^T Z_2)(Z_1^T Z_3)(Z_2^T Z_3)
    = [ E Y_1^2 ]^3 E E[ (Z_1^T Z_2)(Z_1^T Z_3)(Z_2^T Z_3) | k_1,k_2,k_3 ]
    Now, E[ (Z_1^T Z_2)(Z_1^T Z_3)(Z_2^T Z_3) | k ]
	= dirichlet_triden_E( alphavec(k) ),
	where alphavec(k) = [alpha0, alpha0,...,alpha1,...alpha0]
    By symmetry,
    E E[ (Z_1^T Z_2)(Z_1^T Z_3)(Z_2^T Z_3) | k ]
	= Dir( alphavec(k) ) for any k.
    Also, we have for Beta(a,b)
    E Y_1^2 = var(a,b) + mean( a,b)^2,

    Checked with MC simulation, April 29, 2023
    '''

    betamean = beta_mean( K-1, 1 )
    betavar = beta_var( K-1, 1 )
    EY2 = betavar + betamean**2

    # For every combination of mixture assignments, add probability
    diri_triE_mixture = 0.0
    for k1 in range(K):
        alphavec1 = alpha0*np.ones( K )
        alphavec1[k1] = alpha1
        # Now compute Q, as in dirichlet_triden_E
        Q1 = construct_dirichlet_Qmx( alphavec1 )
        for k2 in range(K):
            alphavec2 = alpha0*np.ones( K )
            alphavec2[k2] = alpha1
            Q2 = construct_dirichlet_Qmx( alphavec2 )
            for k3 in range(K):
                alphavec3 = alpha0*np.ones( K )
                alphavec3[k3] = alpha1
                Q3 = construct_dirichlet_Qmx( alphavec3 )
                # Now, computing E X_1^TX_2 X_2^TX_3 X_2^TX_3 is a matrix prod
                diri_triE_mixture += np.trace( Q1 @ Q2 @ Q3 )/(K**3)

    return EY2**3 * diri_triE_mixture

def dirichlet_triden_E( alphavec ):
    '''
    Compute the expected triangle density when latent positions are drawn
    iid from a Dirichlet with vector alphavec.

    alphavec : numpy array encoding a Dirichlet distribution

    Returns: E (X_1^T X_2)(X_1^T X_3)(X_2^T X_3),
                where X_1,X_2,X_3 ~ Dir( alpha ) independently.
    '''

    '''
    Let X ~ Dirichlet( alpha ) and define
    q_{ij} = E X_i X_j.
        = ( alpha_i alpha_j )/( alpha_0 )(alpha_0 + 1) if i neq j
        = ( alpha_i+1) alpha_i /( alpha_0 )(alpha_0 + 1) if i=j.

    So we want to compute
    \sum_{i=1}^d \sum_{j=1}^d \sum_{k=1}^d q_{ij} q_{ik} q_{jk}.
    There are more clever ways to do this, but let's do easy first.

    Verified by MC simulation for alphavec=np.ones(5)
    net.dirichlet_triden_E( alphavec )
        evaluates to 0.008148148148148147
    mean of 1e6 replicates is 0.008174
    mean of 1e7 replicates is 0.0081814
    '''

    Q = construct_dirichlet_Qmx( alphavec )

    # Great. Now all we need to do is retrieve the diagonal entries of Q^3.
    return np.trace( spla.fractional_matrix_power( Q, 3 ) )

def construct_dirichlet_Qmx( alphavec ):
    '''
    Construct the matrix whose entries encode the second moments of
    X = (X_1,X_2,...,X_K) ~ Dirichlet( alphavec )

    e.g., Q_ij = E X_i X_j.
    See https://en.wikipedia.org/wiki/Dirichlet_distribution#Moments
    for formulae.

    Verified by simulation, Jan 21, 2023
    '''

    # Construct a d-by-d matrix whose entries are q_{ij}. 
    Q = np.outer( alphavec, alphavec )
    # Currentl, Q_{ij} = alphai alphaj.
    # Two problems:
    # 1) Currently, Q_ii = alphai^2, but want Q_{ii} = (alphai+1)alphai
    np.fill_diagonal( Q, (alphavec+1)*alphavec )
    # 2) Need to normalize by (alpha0+1)alpha0.
    alpha0 = np.sum(alphavec)
    Qdenom = alpha0*(alpha0+1)
    return Q/Qdenom

def construct_dirichlet_Ztensor( alphavec ):
    '''
    Construct a 3-tensor that has
    z_{ijk} = E X_i X_j X_k
        = ( alpha_i alpha_j alpha_k )/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i,j,k distinct
        = ( (alpha_i+1) alpha_i alpha_k )/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i=j, k!=i,j
        = (alpha_i+2) (alpha_i+1) alpha_i/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i=j=k
    where X = (X_1,X_2,...,X_K) is Dirichlet( alphavec ).

    Verified by simulation, Jan 21, 2023
    '''

    K = alphavec.shape[0]
    alpha0 = np.sum( alphavec )

    # First construct the "easy" part of the K-by-K-by-K Z tensor,
    # namely the off-diagonal entries (we'll fix on-diag below)
    Z = np.einsum('i,j,k->ijk', alphavec, alphavec, alphavec)
    # We need to fix the "on-diagonal" entries, which comes in two types:
    # Z_{i,i,i} and then Z_{i,j,j}, Z_{j,i,j}, Z_{j,j,i}
    for i in range( K ):
        diagvec = alphavec[i]*(alphavec+1)*alphavec
        np.fill_diagonal( Z[i,:,:], diagvec )
        np.fill_diagonal( Z[:,i,:], diagvec )
        np.fill_diagonal( Z[:,:,i], diagvec )
    np.fill_diagonal( Z, (alphavec+2)*(alphavec+1)*alphavec )
    # Renormalize Z.
    Zdenom = (alpha0+2)*(alpha0+1)*alpha0
    return Z/Zdenom

def construct_dirichlet_Vtensor( alphavec ):
    '''
    Construct a 4-tensor that has
    v_ijlm = E X_i X_j X_l X_m
        = alpha_i alpha_j alpha_l alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i,j,l.m distinct
        = alpha_i(alpha_i+1)alpha_l alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j, l,m != i, l != m
        = alpha_i(alpha_i+1)alpha_l(alphal+1)
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j, l,m != i, l=m
        = alpha_i(alpha_i+1)(alpha_i+2)alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j=l, != m
        = alpha_i(alpha_i+1)(alpha_i+2)(alpha_i+3)
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j=l=m
    where X = (X_1,X_2,...,X_K) is Dirichlet( alphavec ).

    Verified by simulation, Jan 21, 2023
    '''

    K = alphavec.shape[0]
    alpha0 = np.sum( alphavec )

    # First construct the "easy" part of the K-by-K-by-K-by-K Z tensor,
    # namely the off-diagonal entries (we'll fix on-diag below)
    V = np.einsum('i,j,k,l->ijkl', alphavec, alphavec, alphavec, alphavec)
    # We need to fix the "on-diagonal" entries, which comes in four types:
    # V_{i,i,i,i}
    # V_{i,i,l,m} where l,m != i, l!=m
    # V_{i,i,m,m} where m != i
    # V_{i,i,i,m} where m != i

    # V_{i,i,l,m} where l,m != i, l!=m
    for l in range( K ):
        for m in range(K):
            diagvec = (alphavec+1)*alphavec*alphavec[m]*alphavec[l]
            np.fill_diagonal( V[l,m,:,:], diagvec )
            np.fill_diagonal( V[l,:,m,:], diagvec )
            np.fill_diagonal( V[l,:,:,m], diagvec )
            np.fill_diagonal( V[:,l,m,:], diagvec )
            np.fill_diagonal( V[:,l,:,m], diagvec )
            np.fill_diagonal( V[:,:,l,m], diagvec )
    # V_{i,i,m,m} where m != i
    for i in range( K ):
        diagvec = (alphavec+1)*alphavec*(alphavec[i]+1)*alphavec[i]
        np.fill_diagonal( V[i,i,:,:], diagvec )
        np.fill_diagonal( V[i,:,i,:], diagvec )
        np.fill_diagonal( V[i,:,:,i], diagvec )
        np.fill_diagonal( V[:,i,i,:], diagvec )
        np.fill_diagonal( V[:,i,:,i], diagvec )
        np.fill_diagonal( V[:,:,i,i], diagvec )
    # V_{i,i,i,m} where m != i
    for i in range( K ):
        diagvec = (alphavec+2)*(alphavec+1)*alphavec*alphavec[i]
        np.fill_diagonal( V[i,:,:,:], diagvec )
        np.fill_diagonal( V[:,i,:,:], diagvec )
        np.fill_diagonal( V[:,:,i,:], diagvec )
        np.fill_diagonal( V[:,:,:,i], diagvec )
    # V_{i,i,i,i}
    np.fill_diagonal( V, (alphavec+3)*(alphavec+2)*(alphavec+1)*alphavec )
    # Renormalize V
    Vdenom = (alpha0+3)*(alpha0+2)*(alpha0+1)*alpha0
    return V/Vdenom

def dirichlet_triden_cross2( alphavec ):
    '''
    Compute the expectation
    E A_ij Ajk Aik  A_ij Ail Ajl
    =
    E A_ij^2 Ajk Aik Ail Ajl for k!=l
    Called "cross2" because there are two
    vertices shared across the two triples.

    alphavec : numpy array encoding a Dirichlet distribution

    Returns:
    E (X_1^T X_2)(X_1^T X_3)(X_2^T X_3)
        (X_1^T X_2)(X_1^T X_4) (X_2^T X_4),
                where X_1,X_2,X_3,X_4 ~ Dir( alpha ) independently.

    Verified by simulation, Jan 21, 2023
    '''

    '''
    Let X ~ Dirichlet( alpha ) and define
    q_{ij} = E X_i X_j
           = ( alpha_i alpha_j )/( alpha_0 )(alpha_0 + 1) if i neq j
           = ( alpha_i+1) alpha_i /( alpha_0 )(alpha_0 + 1) if i=j.
    and
    z_{ijk} = E X_i X_j X_k
        = ( alpha_i alpha_j alpha_k )/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i,j,k distinct
        = ( (alpha_i+1) alpha_i alpha_k )/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i=j, k!=i,j
        = (alpha_i+2) (alpha_i+1) alpha_i/( alpha_0 )(alpha_0 + 1)(alpha_0+2)
                if i=j=k

    We want to compute
    sum_{ijklm} z_{ikl} z_{ijm} q_{jk} q_{lm}
    '''

    K = alphavec.shape[0]

    # Construct the 3-tensor Z
    Z = construct_dirichlet_Ztensor( alphavec )
    # Similarly, construct the Q matrix whose entries are the q_{ij} terms
    Q = construct_dirichlet_Qmx( alphavec )

    # Now we want to sum along the diagonal of a matrix whose entries are
    # M_{i_1, i_2} = \sum_{jklm} Z_{i1,k,l} Z_{i2,j,m} q_{j,k} q_{l,m}
    # There is a fancy tensor way to do this, but let's just get something
    # functional for the time being.
    M = np.zeros( K ) # Just the diagonal of this fictional matrix
    for i in range(K):
        for j in range(K):
            for k in range(K):
                qjk = Q[j,k]
                for l in range(K):
                    Zikl = Z[i,k,l]
                    for m in range(K):
                        qlm = Q[l,m]
                        Zijm = Z[i,j,m]
                        M[i] = M[i] + Zijm*Zikl*qjk*qlm
    return np.sum( M )

def dirichlet_triden_cross1( alphavec ):
    '''
    Compute the expectation
    E A_ij Ajk Aik  A_il Aim Alm
    =
    E A_ij Ajk Aik Ail Aim Alm for i,j,k,l,m distinct
    Called "cross1" because there is one
    vertex shared across the two triples.

    alphavec : numpy array encoding a Dirichlet distribution

    Returns:
    E (X_1^T X_2)(X_1^T X_3)(X_2^T X_3)
        (X_1^T X_4)(X_1^T X_5) (X_4^T X_5),
                where X_1,X_2,X_3,X_4,X_5 ~ Dir( alpha ) independently.

    Verified by simulation, Jan 21 2023
    '''

    '''
    Here we need to compute
    sum_ijklmn V_ijlm q_ik q_jk q_ln q_mn,
    where letting  X ~ Dirichlet( alpha ), define
    q_ik = E X_i X_j
    and
    v_ijlm = E X_i X_j X_l X_m
        = alpha_i alpha_j alpha_l alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i,j,l.m distinct
        = alpha_i(alpha_i+1)alpha_l alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j, l,m != i, l != m
        = alpha_i(alpha_i+1)alpha_l(alphal+1)
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j, l,m != i, l=m
        = alpha_i(alpha_i+1)(alpha_i+2)alpha_m
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j=l, != m
        = alpha_i(alpha_i+1)(alpha_i+2)(alpha_i+3)
                /alpha_0(alpha_0+1)(alpha_0+2)(alpha_0+3)
                if i=j=l=m
    '''

    V = construct_dirichlet_Vtensor( alphavec )

    '''
    Now we need to compute the sum
    sum_ijklmn v_ijlm q_ik q_jk q_ln q_mn
    = sum_ijlm v_ijlm (sum_k q_ik q_jk) (sum_n q_ln q_mn).
    so construct the matrix Qsq = Q @ Q,
    which has Qsq_ij = sum_k q_ik q_jk, so that
    sum_ijklmn v_ijlm q_ik q_jk q_ln q_mn
    = sum_ijlm v_ijlm Qsq_ij Qsq_lm
    '''
    Q = construct_dirichlet_Qmx( alphavec )
    Qsq = Q @ Q

    K = alphavec.shape[0]
    retval = 0.0
    for i in range(K):
        for j in range(K):
            Qsqij = Qsq[i,j]
            for l in range(K):
                for m in range(K):
                    Qsqlm = Qsq[l,m]
                    Vijlm = V[i,j,l,m]
                    retval += Vijlm*Qsqij*Qsqlm

    return retval

def dirichlet_triden_var( n, alphavec ):
    '''
    Compute the variance of the triangle density when latent positions
    are drawn iid from a Dirichlet with vector alphavec.

    alphavec : numpy array encoding a Dirichlet distribution

    Returns: Var T(A), where T(A) = nC3^{-1} \sum_{i,j,k} A_{ij} A_{jk} A_{ik}.

    Following similar calculations to the sbm_oracle.py code, we want to
    compute
    Var T = (nC3)^{-6} Var sum_{i,j,k} A_{ij} A_{jk} A_{ik}

    Three terms contribute to this sum:
    Var T_{123} (where T_{123} = A_{12} A_{23} A_{13} )
    A) Cov( T_{ijk}, T_{ijl} ) (where k != l)
    B) Cov( T_{ijk}, T_{ilm} ( where {j,k} \cap {l,m} = \emptyset )   
       
    Verified with simulation:
    1e6 replicates with n=15,
    truth:  0.00010357693606713023 
    MC var: 0.00013105861
    '''

    # Variance of a single Tijk term is easy, since Tijk^2 = Tijk
    # Agrees with large simulation (30K samples of 3-vx networks)
    Emarginal = dirichlet_triden_E( alphavec )
    varTijk = Emarginal - Emarginal**2

    # Now, to compute the two different cross-terms
    # E Aij^2 Ajk Aik Ail Ajl, k != l
    # cross2 because two of the vertices are shared across the triples.
    expec_cross2 = dirichlet_triden_cross2( alphavec )
    # Compute the covariance term
    covT_2 = expec_cross2 - Emarginal**2

    # Now, the other cross-term:
    # E Aij^2 Aik Ajk Ail Aim Alm, {j,k} \cap {l,m} = \emptyset
    # cross1 because one of the vertices are shared across the triples.
    expec_cross1 = dirichlet_triden_cross1( alphavec )
    covT_1 = expec_cross1 - Emarginal**2

    # Now, we need to account for... counting.
    # Var nC3^{-1} Tijk = var Tijk + 2*nC2 (n-2)C2 nC3^{-2} covT_2
    #                   + 4*3*n (n-1)C4 nC3^{-2} covT_1
    nC2 = spsp.binom(n,2)
    nminus1C4 = spsp.binom(n-1,4)
    nminus2C2 = spsp.binom(n-2,2)
    nC3 = spsp.binom(n,3)
    term2 = 2*nC2 * nminus2C2 * covT_2
    term1 = 4*3*n * nminus1C4 * covT_1
    return ( varTijk + term2 + term1 )/(nC3**2)

def dirimix_triden_ustatvar( nn, K, alpha1, alpha0 ):
    '''
    Compute the variance of a triangle density Ustatistic on n vertices
    when the latent positions are drawn from a mixture of Dirichlets.
    The 9 below comes from arity**2.
    '''
    nn = int(nn)
    if nn < 1:
        raise ValueError('Number of vertices must be nonnegative.')
    return 9*dirimix_triden_h1var( K, alpha1, alpha0 )/nn

def dirimix_triden_h1var( K, alpha1, alpha0 ): 
    '''
    Compute the U-statistic variance,
    Var h_1(X), where
    h_1(x) = E_{Y,Z} h(x, Y, Z), and h(x,y,z) = x^T y y^T z x^T z
    and X,Y,Z are iid from a mixture of Dirichlets
    '''

    '''
    So we first need to compute
    E_{Y,Z} h(x, Y, Z)
    as a function of x.

    That would be
    sum_{j1,j2,j3} x_j1 x_j2 (\E Y_j1 Y_j3)(\E Z_j2 Z_j3 )

    Since $Y,Z are independent diri mixtures, we know how to compute these:
    https://en.wikipedia.org/wiki/Dirichlet_distribution#Moments
    letting G be a Beta( K-1, 1 ),
    E \prod_i (B Y)_i^{beta_i}
    = E G^|beta| E \prod_i Y_i^{beta_i}
    = [|beta|-th moment of Beta(K-1,1)]*[mixture of Betas]

    In other words, we need the variance of
    h_1(x) = x^T V x, where
    V_{j1,j2} = \sum_j3 (\E Y_j1 Y_j3)(\E Z_j2 Z_j3 ),
    where x ~ Dirichlet( alphavec )
    letting B_i,j = E Y_i Y_j for Y ~ DiriMix,
    that would be
    h_1(x) = x^T V x = x^T V x.
    '''

    # So first we need to compute V.
    B = compute_dirimix_2ndmoment_mx( K, alpha1, alpha0 )
    V = B.T @ B
    Eh1x = (V.T @ B).trace()

    '''
    # Then we also need to compute the expectation of
    # E ( sum_j1,j2 B_{j1,j2} X_j1 X_j2 )^2
    # = sum_j1,j2,j3,j4 B_{j1,j2} B_{j3,j4} E X_j1 X_j2 X_j3 X_j4
    '''
    Eh1xsquared = compute_dirimix_Eh1Xsquared( K, alpha1, alpha0 )

    return Eh1xsquared - Eh1x**2 # Serfling 5.5.1 A

def compute_dirimix_Eh1Xsquared( K, alpha1, alpha0 ):
    '''
    Compute Eh_1^2 (X), where X~DiriMix and h_1(x) = E_{Y,Z} h(x,Y,Z).
    for h(x,y,z) = x^Ty y^Tz z^Tx.
    
    We have
    h_1(x) = E_{Y,Z} h(x,Y,Z) = x^T B^T B x, where B_ij = E Y_i Y_j.
    So, with V_ij = (B^T B)_ij,
    h_1(x)^2 = ( \sum_j1,j2 x_j1 V_j1,j2 x_j2 )^2
        = \sum_j1,j2,j3,j4 V_{j1,j2} V_{j3,j4} x_j1 x_j2 x_j3 x_j4

    '''
    B = compute_dirimix_2ndmoment_mx( K, alpha1, alpha0 )
    V = B.T @ B
    
    # Then we also need to compute the expectation of
    # E ( sum_j1,j2 V_{j1,j2} X_j1 X_j2 )^2
    # = sum_j1,j2,j3,j4 V_{j1,j2} V_{j3,j4} E X_j1 X_j2 X_j3 X_j4
    # So let's create an order-4 array with entries
    # F[j1,j2,j3,j4] = E X_j1 X_j2 X_j3 X_j4.
    F = compute_dirimix_4thmoment_mx( K, alpha1, alpha0 )
    # and now we need to compute
    # "vecV^T F vecV", which we'll do the clumsy way.
    Eh1xsquared = 0.0
    for j1 in range(K):
        for j2 in range(K):
            for j3 in range(K):
                for j4 in range(K):
                    Eh1xsquared += V[j1,j2]*V[j3,j4]*F[j1,j2,j3,j4]
    return Eh1xsquared

def compute_dirimix_4thmoment_mx( K, alpha1, alpha0 ):
    '''
    Create an order-4 array with entries
    F[j1,j2,j3,j4] = E X_j1 X_j2 X_j3 X_j4.
    when X ~ DiriMix
    '''
    F = np.zeros( (K,K,K,K) )
    for j1 in range(K):
        for j2 in range(K):
            for j3 in range(K):
                for j4 in range(K):
                    # Construct vector of power
                    betavec = np.zeros( K )
                    betavec[j1] += 1
                    betavec[j2] += 1
                    betavec[j3] += 1
                    betavec[j4] += 1
                    # Compute corresponding moment and update F
                    for kk in range(K):
                        alphavec = alpha0*np.ones( K )                    
                        alphavec[kk] = alpha1
                        forth = compute_diri_moment( alphavec, betavec )
                        F[j1,j2,j3,j4] += forth/K
    return F
    

def compute_dirimix_2ndmoment_mx( K, alpha1, alpha0 ):
    '''
    Compute a matrix B whose entries are
    B_{ij} = E Y_i Y_j where Y ~ MixDiri,
    where mixture is over K different rotationally symmetric vectors
    ( alpha0, ..., alpha0, alpha1, alpha0, ..., alpha0 ).
    By symmetry, this is just our usual 2nd moment matrix,
    with appropriate choice of alphavec.
    '''

    # Our matrix is now a mixture of 2nd moment matrices,
    # integrating over the mixture component.
    B = np.zeros( (K,K) )
    for k in range(K):
        alphavec = alpha0*np.ones(K)
        alphavec[k] = alpha1 
        B += compute_diri_2ndmoment_mx( alphavec )/K
    return B

def diri_triden_ustatvar( nn, alphavec ):
    '''
    Compute the variance of a triangle density Ustatistic on n vertices.
    The 9 below comes from arity**2.
    '''
    nn = int(nn)
    if nn < 1:
        raise ValueError('Number of vertices must be nonnegative.')
    return 9*diri_triden_h1var( alphavec )/nn

def diri_triden_h1var( alphavec ):
    '''
    Compute the U-statistic variance,
    Var h_1(X), where
    h_1(x) = E_{Y,Z} h(x, Y, Z), and h(x,y,z) = x^T y y^T z x^T z
    '''

    '''
    So we first need to compute
    E_{Y,Z} h(x, Y, Z)
    as a function of x.

    That would be
    sum_{j1,j2,j3} x_j1 x_j2 (\E Y_j1 Y_j3)(\E Z_j2 Z_j3 )
    Since $Y,Z are independent Dir(alphavec), we know how to compute these:
    https://en.wikipedia.org/wiki/Dirichlet_distribution#Moments
    E \prod_i Y_i^{beta_i} = B( alphavec, betavec) / B( alphavec )

    In other words, we need the variance of
    h_1(x) = x^T V x, where
    V_{j1,j2} = \sum_j3 (\E Y_j1 Y_j3)(\E Z_j2 Z_j3 ),
    where x ~ Dirichlet( alphavec )
    letting B_i,j = E Y_i Y_j for Y ~ Dirichlet,
    that would be
    h_1(x) = x^T V x = x^T V x.
    '''

    # The expectation of this thing would then be
    # sum_j1,j2 V_{j1,j2} E X_j1 X_j2, i.e. trace V^T B
    # Verified experimentally, April 9, 2023.
    # NMC=1e6, MCmean 0.089438... Eh1x 0.089259219
    B = compute_diri_2ndmoment_mx( alphavec )
    V = B.T @ B
    Eh1x = (V.T @ B).trace()

    '''
    # Then we also need to compute the expectation of
    # E ( sum_j1,j2 B_{j1,j2} X_j1 X_j2 )^2
    # = sum_j1,j2,j3,j4 B_{j1,j2} B_{j3,j4} E X_j1 X_j2 X_j3 X_j4
    '''
    Eh1xsquared = compute_Eh1Xsquared( alphavec )

    return Eh1xsquared - Eh1x**2 # Serfling 5.5.1 A

def compute_Eh1Xsquared( alphavec ):
    '''
    Compute Eh_1^2 (X), where X~Dir(alphavec) and h_1(x) = E_{Y,Z} h(x,Y,Z).
    for h(x,y,z) = x^Ty y^Tz z^Tx.
    
    We have
    h_1(x) = E_{Y,Z} h(x,Y,Z) = x^T B^T B x, where B_ij = E Y_i Y_j.
    So, with V_ij = (B^T B)_ij,
    h_1(x)^2 = ( \sum_j1,j2 x_j1 V_j1,j2 x_j2 )^2
        = \sum_j1,j2,j3,j4 V_{j1,j2} V_{j3,j4} x_j1 x_j2 x_j3 x_j4

    Verified by MC estimation, 1e6 samples, agrees to four decimal places
	April 11, 2023
    '''
    K = len( alphavec )
    B = compute_diri_2ndmoment_mx( alphavec )
    V = B @ B
    
    # Then we also need to compute the expectation of
    # E ( sum_j1,j2 V_{j1,j2} X_j1 X_j2 )^2
    # = sum_j1,j2,j3,j4 V_{j1,j2} V_{j3,j4} E X_j1 X_j2 X_j3 X_j4
    # So let's create an order-4 array with entries
    # F[j1,j2,j3,j4] = E X_j1 X_j2 X_j3 X_j4.
    F = compute_diri_4thmoment_mx( alphavec )
    # and now we need to compute
    # "vecV^T F vecV", which we'll do the clumsy way.
    Eh1xsquared = 0.0
    for j1 in range(K):
        for j2 in range(K):
            for j3 in range(K):
                for j4 in range(K):
                    Eh1xsquared += V[j1,j2]*V[j3,j4]*F[j1,j2,j3,j4]
    return Eh1xsquared

def compute_diri_2ndmoment_mx( alphavec ):
    K = len( alphavec )
    B = np.zeros( (K,K) )
    for j1 in range(K):
        for j2 in range(K):
            #B[j1,j2] = compute_diri_secondmoment( alphavec, j1, j2 )
            betavec = np.zeros( K )
            betavec[j1] += 1
            betavec[j2] += 1
            B[j1,j2] = compute_diri_moment( alphavec, betavec )
    return B

def compute_diri_4thmoment_mx( alphavec ):
    '''
    Create an order-4 array with entries
    F[j1,j2,j3,j4] = E X_j1 X_j2 X_j3 X_j4.
    '''
    K = len( alphavec )
    F = np.zeros( (K,K,K,K) )
    for j1 in range(K):
        for j2 in range(K):
            for j3 in range(K):
                for j4 in range(K):
                    # Construct vector of power
                    betavec = np.zeros( K )
                    betavec[j1] += 1
                    betavec[j2] += 1
                    betavec[j3] += 1
                    betavec[j4] += 1
                    # Compute corresponding moment and update F
                    F[j1,j2,j3,j4] = compute_diri_moment( alphavec, betavec )
    return F

def compute_diri_moment( alphavec, betavec ):
    '''
    Return E prod_i X_i^{betavec[i]), where X ~ Diri( alphavec )
    '''

    K = len( alphavec )
    alphavec_aug = np.zeros( K )
    for k in range(K):
        if betavec[k] < 0:
            raise ValueError('Powers in betavec must be positive')
        alphavec_aug[k] = alphavec[k] + betavec[k]
    numer = spsp.gamma( np.sum( alphavec ) )
    denom = spsp.gamma( np.sum( alphavec_aug ) )
    for k in range(K):
        numer = numer*spsp.gamma( alphavec_aug[k] )
        denom = denom*spsp.gamma( alphavec[k] )
    return numer/denom

def compute_diri_X4( alphavec, j1 ):
    # Return E X_j1^4 where X ~ Diri( alphavec )
    numer = spsp.gamma( np.sum( alphavec ) )*spsp.gamma( alphavec[j1]+4 )
    denom = spsp.gamma( np.sum( alphavec_aug ) )*spsp.gamma( alphavec[j1] )
    return numer/denom

def compute_diri_mean( alphavec ):
    # See https://en.wikipedia.org/wiki/Dirichlet_distribution
    # for mean vector of Dirichlet.
    # E X_i = alpha_i/sum_j alpha_j
    return alphavec/np.sum(alphavec)

